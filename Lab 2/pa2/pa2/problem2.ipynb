{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4f35e3b",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef50ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762abab6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8753048a-08d4-4a2e-b750-50e923c15f22",
   "metadata": {},
   "source": [
    "## CSL2050: Pattern Recognition and Machine Learning<br>\n",
    "Programming Assignment-2<br>\n",
    "Spring 2025<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e7297f-a2a2-4927-8501-35db45807ac8",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "In this assignment, we will explore linear regression by implementing fundamental modules such as Mean Squared Error (MSE), Gradient Descent, and Prediction. These building blocks will then be utilized to experiment with a real-world dataset for solving a linear regression problem. Please ensure that you solve the problems sequentially for a structured learning experience. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9969ec7-b433-47a9-a564-d9a99a513598",
   "metadata": {},
   "source": [
    "**Problem-2.01:** Write a function mean_squared_error(y_true, y_pred) that calculates the Mean Squared Error (MSE) between the true values y_true and predicted values y_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9b1d59-496d-4cea-9159-3db30701fed5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9724d3c94bc4f006ca6bd3d634a687fa",
     "grade": false,
     "grade_id": "mean_squared_error",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Squared Error between true and predicted values.\n",
    "\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): True values of shape (n_samples,).\n",
    "        y_pred (numpy.ndarray): Predicted values of shape (n_samples,).\n",
    "\n",
    "    Returns:\n",
    "        float: Mean Squared Error.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406cecb0-59dd-4a44-a0a2-58b5f6e02549",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b3a7be20581874715c66eb8487fec74",
     "grade": true,
     "grade_id": "mean_squared_error_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Visible Test Case\n",
    "import numpy as np\n",
    "y_true = np.array([1.0, 2.0, 3.0])\n",
    "y_pred = np.array([1.0, 2.0, 3.0])\n",
    "assert mean_squared_error(y_true, y_pred) == 0, \"Test Case 1 Failed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c5ec4-4583-4b59-bc97-0e7ea81be768",
   "metadata": {},
   "source": [
    "**Problem-2.02:** Write a function ols_coefficients(X, y) that calculates the coefficients for a simple linear regression problem using the Ordinary Least Squares (OLS) formula. Note: Coefficient in hyperplane \\theta_0+\\theta_1x_1+\\theta_2x_2 are \\theta_0, \\theta_1 and \\theta_2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b1fadd-3545-4c29-a082-49238f418285",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2db5c514b1dc664de9001f41cf424a5a",
     "grade": false,
     "grade_id": "ols_coefficients",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ols_coefficients(X, y):\n",
    "    \"\"\"\n",
    "    Calculate the OLS coefficients for linear regression.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): Feature matrix of shape (n_samples, n_features).\n",
    "        y (numpy.ndarray): Target vector of shape (n_samples,).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Coefficients of shape (n_features + 1,).\n",
    "                       The first value is the intercept, and the rest are feature coefficients.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab71fea-2dc4-4900-8ddd-c8dcb8471717",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef8d1339b318e0102592a84b667a9a01",
     "grade": true,
     "grade_id": "ols_coefficients_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install pytest\n",
    "import pytest\n",
    "# Test case 1: Single feature, no intercept\n",
    "def test_case_1():\n",
    "    X = np.array([[1], [2], [3]])\n",
    "    y = np.array([2, 4, 6])\n",
    "    expected = np.array([0., 2.])  # y = 2x\n",
    "    np.testing.assert_almost_equal(ols_coefficients(X, y), expected, decimal=6)\n",
    "\n",
    "# Test case 2: Single feature, with intercept\n",
    "def test_case_2():\n",
    "    X = np.array([[1], [2], [3]])\n",
    "    y = np.array([3, 5, 7])\n",
    "    expected = np.array([1., 2.])  # y = 1 + 2x\n",
    "    np.testing.assert_almost_equal(ols_coefficients(X, y), expected, decimal=6)\n",
    "\n",
    "test_case_1()\n",
    "test_case_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db79e214-d953-48f7-afda-deffb13fb729",
   "metadata": {},
   "source": [
    "**Problem-2.03:** Implement a function gradient_descent(X, y, lr, epochs) to perform gradient descent for linear regression.\n",
    "\n",
    "Given a feature matrix X of shape (n_samples,n_features) a target vector y of shape (n_samples,), a learning rate lr, and the number of iterations epochsepochs, your task is to iteratively update the coefficients θ to minimize the mean squared error between the predicted and actual target values.\n",
    "\n",
    "The function should return the optimized coefficients θ, which are of shape (n_features+1,). (Note the line/hyperplan has equations like θ_0 + θ_1x_1 + θ_2x_2 + ....+θ_nx_n=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff146ab6-6872-4032-99aa-3d78871b3c3b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "497d25fe66401c5238b24cd6458eae81",
     "grade": false,
     "grade_id": "gradient_descent",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, lr, epochs):\n",
    "    \"\"\"\n",
    "    Perform gradient descent for linear regression.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): Feature matrix of shape (n_samples, n_features).\n",
    "        y (numpy.ndarray): Target vector of shape (n_samples,).\n",
    "        lr (float): Learning rate.\n",
    "        epochs (int): Number of iterations.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Optimized coefficients of shape (n_features+1).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb36687-bc18-412d-842a-953db6ad20ed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1752e624ded63b40693df419109b115",
     "grade": true,
     "grade_id": "gradient_descent_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test case 1: Simple case with one feature and bias term\n",
    "def test_case_1():\n",
    "    X = np.array([[1], [2], [3]])\n",
    "    y = np.array([2, 4, 6])  # Perfectly linear relationship y = 2x\n",
    "    lr = 0.01\n",
    "    epochs = 1000\n",
    "    theta = gradient_descent(X, y, lr, epochs)\n",
    "    # Assert bias and slope\n",
    "    assert np.abs(theta[0] - 0) < 0.5, f\"term {theta[0]} is not close enough to 0\"\n",
    "    assert np.abs(theta[1] - 2) < 0.5, f\"term {theta[1]} is not close enough to 2\"\n",
    "test_case_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2c72c6-110d-4af0-bf23-146cd4c8b030",
   "metadata": {},
   "source": [
    "**Problem-2.04:** Write a function predict(X, theta) that predicts the target values y for each sample of a given feature matrix X and the learned coefficients θ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4009de-260a-4f49-baac-4f6a28330019",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a14535d976f1a7d6eeec77b7c0c5623",
     "grade": false,
     "grade_id": "predict",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    \"\"\"\n",
    "    Predict target values for given features and coefficients.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): Feature matrix of shape (n_samples, n_features).\n",
    "        theta (numpy.ndarray): Coefficients of shape (n_features,).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Predicted values of shape (n_samples,).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8def26a-cd16-42fa-a1dd-b1b9204967a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec6d80e6467c72e8629a5b83f1c2fcf6",
     "grade": true,
     "grade_id": "predict_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Test case 1: Single feature, single sample\n",
    "def test_case_1():\n",
    "    X = np.array([[2]])  # Single sample with one feature\n",
    "    theta = np.array([1, 2])  # Bias = 1, Coefficient = 2\n",
    "    expected = np.array([5])  # Prediction: 1 + 2*2 = 5\n",
    "    np.testing.assert_almost_equal(predict(X, theta), expected, decimal=6)\n",
    "\n",
    "# Test case 2: Single feature, multiple samples\n",
    "def test_case_2():\n",
    "    X = np.array([[1], [2], [3]])  # Three samples, one feature\n",
    "    theta = np.array([0.5, 1.5])  # Bias = 0.5, Coefficient = 1.5\n",
    "    expected = np.array([2.0, 3.5, 5.0])  # Predictions: 0.5 + 1.5*X\n",
    "    np.testing.assert_almost_equal(predict(X, theta), expected, decimal=6)\n",
    "\n",
    "test_case_1()\n",
    "test_case_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ec0084-c4fe-4407-aae9-719f0fe2bf5f",
   "metadata": {},
   "source": [
    "**Problem-2.05:** Putting it all together, now we can write a function that leverages the previously implemented functions, including Mean Squared Error (MSE), gradient descent, and prediction, and perform linear regression using gradient descent (assuming MSE loss). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e787219f-0e4a-43c5-ab6b-851381fdf7db",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f56011aa682286909deb6b30358b9729",
     "grade": false,
     "grade_id": "LinearRegressionUsingGD",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def LinearRegressionUsingGD(X,y,lr, epochs):\n",
    "  theta=gradient_descent(X, y, lr, epochs)\n",
    "  predictions=predict(X,theta)\n",
    "  #Write appropriate return statement\n",
    "  # YOUR CODE HERE\n",
    "  raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74502d48-b6c2-4d49-89e2-fa01a7c09c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1], [2], [3]])  \n",
    "y = np.array([1, 2, 3])\n",
    "\n",
    "theta, predictions = LinearRegressionUsingGD(X,y,lr=0.01, epochs=1000)\n",
    "\n",
    "print(\"Coefficients:\", theta)\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b4e04a-6873-445b-8c5c-75793451eb82",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3204f3d1fc52cda614983ca810c29c0d",
     "grade": true,
     "grade_id": "LinearRegressionUsingGD_test",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Test Case 1: Simple linear regression with a single feature\n",
    "def test_case_1():\n",
    "    X = np.array([[1], [2], [3]])  # Feature matrix\n",
    "    y = np.array([1, 2, 3])  # Target values\n",
    "\n",
    "    theta, predictions = LinearRegressionUsingGD(X,y,lr=0.01, epochs=1000)\n",
    "    \n",
    "    # Calculate residuals\n",
    "    residuals = np.abs(predictions - y)\n",
    "\n",
    "    # Assert that residuals are very small (e.g., less than 0.01)\n",
    "    np.testing.assert_array_less(residuals, np.full_like(residuals, 0.4))\n",
    "    \n",
    "test_case_1()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6155da-f8d5-4122-bbaf-84c173c9ac46",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67eb9395d181a4c30c4e89cbdc15aa1f",
     "grade": false,
     "grade_id": "realWorldData",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**Problem-2.06:** Leverage your implementation and choose any real word regression dataset of your choice. Split the data into 80-10-10% of train-val-test. Report train and test MSE of your linear regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51931df-3ced-4e0a-90bb-563a67bccc8a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57cb8b9694569192581c273dde2f8e4a",
     "grade": false,
     "grade_id": "Insights",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**Problem-2.07:** Which dataset you have chosen for Problem-2.6. Expalin briefly about the task in the dataset. How does your test error changes with training datasize, explore and report quantitative analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea863d5-dba1-4472-8765-0318765ad746",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd652301fde70fe42609457b34852ad8",
     "grade": false,
     "grade_id": "ethics",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**Problem-2.08:** Ethical Reflection and Acknowledgments (Mandatory Question) (i) List all collaborators, references, or resources you used. If none, write \"NA.\"\n",
    "\n",
    "(ii) Estimate the percentage of the code you wrote yourself.\n",
    "\n",
    "(iii) Reflect on your ethical practices (Yes/No):\n",
    "\n",
    "(a) Did you avoid copying code without understanding it?\n",
    "(b) Did you properly cite all resources and collaborators?\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
